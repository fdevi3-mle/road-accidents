{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10528861,"sourceType":"datasetVersion","datasetId":6515048}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:31.753884Z","iopub.execute_input":"2025-01-27T08:13:31.754240Z","iopub.status.idle":"2025-01-27T08:13:32.149565Z","shell.execute_reply.started":"2025-01-27T08:13:31.754200Z","shell.execute_reply":"2025-01-27T08:13:32.148713Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/france-road-merged/merged-vehicles-users-places-characteristics_2025_01_06_2138.csv\n/kaggle/input/france-road-merged/preprocessedMerged-_2025_01_20_1655.parquet\n/kaggle/input/france-road-merged/merged-vehicles-users-places-characteristics_2025_01_06_2141.parquet\n/kaggle/input/france-road-merged/merged-vehicles-users-places-characteristics_2025_01_06_2140.feather\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%time\n## all imports\nimport polars as pl\nimport pyarrow.parquet as pq\nimport dask.dataframe as dd\nimport os\nimport shutil\nimport json\nfrom enum import Enum\nfrom datetime import datetime\nfrom ydata_profiling import ProfileReport\nfrom pathlib import Path\nimport random\nimport hdbscan\nimport pyarrow\n\nfrom dask.distributed import LocalCluster\n##Metrics\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\nfrom sklearn.metrics import mutual_info_score, adjusted_rand_score\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n\nimport plotly.express as px\n#For excel stuff\nimport openpyxl\nfrom openpyxl.drawing.image import Image\n\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Concurrency\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\nimport time\n\n#  Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random state\nrandom_state = 42\n# Set figure size\nplt.rcParams[\"figure.figsize\"] = (20, 20)\n\n\nclass ExtensionMethods:\n    @staticmethod\n    def generate_filename(filename=None,extension=None):\n        current_datetime = datetime.now()\n        f = current_datetime.strftime(\"%Y_%m_%d_%H%M\")\n        if (filename is None) or (extension is None):\n            return str(f)\n        else:\n            stitched_f = str(filename)+\"_\"+str(f)+\".\"+str(extension)\n            return str(stitched_f)\n\n    @staticmethod\n    def get_file_name_without_extension(filename):\n        if filename == None:\n            return \"Provide a file\"\n        return Path(filename).stem\n\n\nfeather_file = '/kaggle/input/france-road-merged/merged-vehicles-users-places-characteristics_2025_01_06_2140.feather'\nparquet_file = '/kaggle/input/france-road-merged/merged-vehicles-users-places-characteristics_2025_01_06_2141.parquet'\ncsv_file = '/kaggle/input/france-road-merged/merged-vehicles-users-places-characteristics_2025_01_06_2138.csv'\npre_file= '/kaggle/input/france-road-merged/preprocessedMerged-_2025_01_20_1655.parquet'\n\n\ndef explore_dataframe(df):\n    \"\"\"\n    Prints basic information about the dataframe.\n    Args:\n        df : Data frame\n        #TODO : exception handling later\n    \"\"\"\n\n    # Basic information\n    print(\"DataFrame Info:\")\n    df.info()\n\n    #Null counts\n    print(\"\\nNull Values per Column:\")\n    null_counts = df.isnull().sum()\n    print(null_counts)\n\n    # Normal values per column\n    print(\"\\nNormal Values per Column:\")\n    normal_counts = df.notnull().sum()\n    print(normal_counts)\n\n    # Descriptive stuff\n    print(\"\\nDescriptive Statistics:\")\n    print(df.describe(include='all'))\n\n    # Value counts for cat stuff\n    categorical_cols = df.select_dtypes(include=['object']).columns\n    print(\"\\nValue Counts for Categorical Columns:\")\n    for col in categorical_cols:\n        print(f\"\\nColumn: {col}\")\n        print(df[col].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:32.150523Z","iopub.execute_input":"2025-01-27T08:13:32.150983Z","iopub.status.idle":"2025-01-27T08:13:39.648818Z","shell.execute_reply.started":"2025-01-27T08:13:32.150955Z","shell.execute_reply":"2025-01-27T08:13:39.647629Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hdbscan'"],"ename":"ModuleNotFoundError","evalue":"No module named 'hdbscan'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_parquet(pre_file)\ndf.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.649812Z","iopub.execute_input":"2025-01-27T08:13:39.650394Z","iopub.status.idle":"2025-01-27T08:13:39.671237Z","shell.execute_reply.started":"2025-01-27T08:13:39.650362Z","shell.execute_reply":"2025-01-27T08:13:39.667691Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-4ee7cb98ea4b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pre_file' is not defined"],"ename":"NameError","evalue":"name 'pre_file' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"class CategoryBaseEnum(Enum):\n    @classmethod\n    def Name(cls):\n        return f\"{cls.__name__}\"\n    @classmethod\n    def IsCategory(cls):\n        return(True if len(cls.__members__)>0 else False)\n    @classmethod\n    def get_description(cls):\n        return cls.__doc__ or \"No description available\"\n    @classmethod\n    def to_dict(cls):\n        return {member.name:member.value for member in cls}\n    @classmethod\n    def to_json(cls, indent=4):\n        return json.dumps(cls.to_dict(), indent=indent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.671825Z","iopub.status.idle":"2025-01-27T08:13:39.672140Z","shell.execute_reply":"2025-01-27T08:13:39.672015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FileTypeEnum(Enum):\n    @classmethod\n    def Name(cls):\n        return f\"{cls.__name__}\"\n    @classmethod\n    def get_description(cls):\n        return cls.__doc__ or \"No description available\"\n    @classmethod\n    def to_dict(cls):\n        return {\n            member.name:member.value.to_dict() for member in cls}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.673106Z","iopub.status.idle":"2025-01-27T08:13:39.673564Z","shell.execute_reply":"2025-01-27T08:13:39.673351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nclass Road_Accident_Enum(FileTypeEnum):\n    '''Collection of all the categories for file type 'vehicle.csv' '''\n\n    class Num_Acc(CategoryBaseEnum):\n        '''The Index/Number of the Crash follows the pattern yyyyxxxxx and is the index column''' \n    class id_vehicule(CategoryBaseEnum):\n        '''The vehicle id  in terms of xxx-xxx'''\n    \n    class catv(CategoryBaseEnum): # catv Vehicle Category\n        '''The Category of Vehicle involved in the crash'''\n        UNDETERMINED = 0\n        BICYCLE = 1\n        MOPED_LESS_EQUAL_50CC = 2\n        MICROCAR = 3\n        TOURISM_VEHICLE = 7\n        UTILITY_VEHICLE_PTAC_1_5T_3_5T = 10 #1.5<PTAC<3.5\n        HEAVY_TRUCK_PTAC_3_5T_7_5T = 13\n        HEAVY_TRUCK_PTAC_OVER_7_5T = 14\n        HEAVY_TRUCK_OVER_3_5T_WITH_TRAILER = 15\n        TRACTOR_ONLY = 16\n        TRACTOR_WITH_SEMI_TRAILER = 17\n        SPECIAL_VEHICLE = 20\n        AGRICULTURAL_TRACTOR = 21\n        SCOOTER_LESS_EQUAL_50CC = 30\n        MOTORCYCLE_50CC_125CC = 31\n        SCOOTER_50CC_125CC = 32\n        MOTORCYCLE_OVER_125CC = 33\n        SCOOTER_OVER_125CC = 34\n        LIGHT_QUAD_LESS_EQUAL_50CC = 35\n        HEAVY_QUAD_OVER_50CC = 36\n        BUS = 37\n        COACH = 38\n        TRAIN = 39\n        TRAMWAY = 40\n        THREE_WHEELED_VEHICLE_LESS_EQUAL_50CC = 41\n        THREE_WHEELED_VEHICLE_50CC_125CC = 42\n        THREE_WHEELED_VEHICLE_OVER_125CC = 43\n        MOTORIZED_PERSONAL_TRANSPORT = 50\n        NON_MOTORIZED_PERSONAL_TRANSPORT = 60\n        OTHER_VEHICLE = 99\n\n    class obs(CategoryBaseEnum):  #obs Static ObstacleHit\n        ''' The Static/Stationary Obstacle Hit'''\n        UNKNOWN = 0\n        PARKED_VEHICLE = 1\n        TREE_ON_ROADSIDE = 2\n        METAL_BARRIER = 3\n        CONCRETE_BARRIER = 4\n        OTHER_BARRIER=5\n        BUILDING_WALL_BRIDGE_PIER = 6 #BUILDING, WALL OR BRIDGE PIER\n        VERTICAL_SIGNPOST_OR_EMERGENCY_CALLBOX = 7\n        POLE = 8\n        URBAN_FURNITURE = 9 # NO CLUE WHAT URBAN FURNITURE\n        PARAPET = 10\n        REFUGE_ISLAND_BOLLARD = 11 #THE ROAD ISLAND / BOLLARD\n        SIDEWALK = 12 #SIDEWALK OR CURB\n        DITCH = 13 #DITCH OR EMBANKMENT\n        OTHER_OBS_ON_ROADWAY = 14\n        OTHER_OBS_ON_SIDEWALK = 15\n        ROADWAY_EXIT_WITOUT_OBSTACLES = 16\n        AQUEDUCT_HEAD = 17\n\n    class obsm(CategoryBaseEnum): #obsm #Mobile obstacle hit\n        '''The Dynamic Obstacle Hit'''\n        UNKNOWN = 0\n        PEDESTRIAN =1 \n        VEHICLE = 2\n        RAIL_VEHICLE = 3\n        ANIMAL_DOMESTIC = 4\n        ANIMAL_WILD = 5\n        OTHER = 9\n        \n    class choc(CategoryBaseEnum): #choc Initial Point of Impact\n        '''The Initial Point of Impact of the crash'''\n        UNKNOWN = 0\n        FRONT = 1\n        FRONT_LEFT = 2\n        FRONT_RIGHT = 3\n        REAR = 4\n        REAR_RIGHT = 5\n        REAR_LEFT = 6\n        SIDE_LEFT = 7\n        SIDE_RIGHT = 8\n        MULTIPLE = 9\n\n    \n    class manv(CategoryBaseEnum): #manv , Main action before crash\n        '''The Main Action performed by the user before the crash'''\n        UNKNOWN = 0\n        CIRCULATING_NO_DIRECTION_CHANGE =1\n        CIRCULATING_SAME_DIRECTION = 2 #SAME DIRECTION SAME LANE\n        CIRCULATION_BETWEEN_2_LANES = 3\n        CIRCULATING_REVERSING = 4\n        CIRCULATING_AGAINTS_FLOW_TRAFFIC = 5\n        CIRCULATING_CROSSING_MEDIAN_STRIP = 6\n        CIRCULATING_IN_BUSLANE_SAME_DIRECTION = 7\n        CIRCULATING_IN_BUSLANE_OPP_DIRECTION = 8\n        CIRCULATING_INSERTION =9\n        CIRCULATING_TURNING_AROUND_CARRIAGE_WAY = 10\n        CHANGING_LANE_LEFT = 11\n        CHANGING_LANE_RIGHT = 12\n        DEPORT_LEFT = 13\n        DEPORT_RIGHT = 14\n        TURNING_LEFT = 15\n        TURNING_RIGHT = 16\n        OVERTAKING_LEFT = 17\n        OVERTAKING_RIGHT = 18 \n        #VARIOUS S\n        CROSSING_ROAD = 19\n        PARKING_ACTION = 20\n        AVOIDANCE_ACTION = 21\n        DOOR_OPENED = 22\n        STOP_NO_PARKING = 23\n        PARKED_WITH_PASS = 24 # PARKED WITH PASSANGERS\n        DRIVING_SIDEWALK = 25\n        OTHER_ACTIONS = 26\n        \n    \n    class motor(CategoryBaseEnum): # motor\n        '''The Type of Motor(In terms of fuel type) involved in the crash'''\n        UNKNOWN = 0\n        CONVENTIONAL_FUEL = 1 # PETROL, DIESEL ,ETC\n        HYBRID_ELECTRIC = 2\n        ELECTRIC = 3\n        HYDROGEN = 4\n        HUMAN_POWERED = 5\n        OTHER = 6\n\n    class catr(CategoryBaseEnum):\n        '''Category of the road'''\n        MOTORWAY = 1\n        NATIONAL_ROAD = 2\n        DEPARTMENTAL_ROAD = 3\n        MUNICIPAL_ROAD = 4\n        OFF_NETWORK = 5\n        PARKING_AREA = 6\n        URBAN_METROPOLE_ROAD = 7\n        OTHER = 9\n\n    class circ(CategoryBaseEnum):\n        '''Traffic regime:'''\n        NOT_PROVIDED = -1\n        ONE_WAY = 1\n        BIDIRECTIONAL = 2\n        SEPARATE_LANES = 3\n        VARIABLE_LANE = 4\n       \n    class vosp(CategoryBaseEnum):\n        '''Indicates the existence of a reserved lane, regardless of whether or not the accident occurs on this lane.'''\n        NOT_PROVIDED = -1\n        NOT_APPLICABLE = 0\n        CYCLE_TRACK = 1\n        CYCLE_LANE = 2\n        RESERVED_LANE = 3\n        \n    class prof(CategoryBaseEnum):\n        '''Longitudinal profile describes the slope of the road at the location of the accident:'''\n        NOT_PROVIDED = -1\n        FLAT = 1\n        SLOPE = 2\n        CREST = 3\n        BOTTOM = 4\n\n    class plan(CategoryBaseEnum):\n        '''Plan layout'''\n        NOT_PROVIDED = -1\n        STRAIGHT_PART = 1\n        CURVE_LEFT = 2\n        CURVE_RIGHT = 3\n        S_SHAPE = 4\n        \n    class surf(CategoryBaseEnum):\n        '''Surface condition'''\n        NOT_PROVIDED = -1\n        NORMAL = 1\n        WET = 2\n        PUDDLES = 3\n        FLOODED = 4\n        SNOWY = 5\n        MUDDY = 6\n        ICY = 7\n        GREASE = 8\n        OTHER = 9\n       \n    class infra(CategoryBaseEnum):\n        '''Development - Infrastructure:'''\n        NOT_PROVIDED = -1\n        NONE = 0\n        UNDERGROUND = 1\n        BRIDGE = 2\n        INTERCHANGE_RAMP = 3\n        RAILROAD = 4\n        AMENAGED_CROSSROAD = 5\n        PEDESTRIAN_ZONE = 6\n        TOLL_ZONE = 7\n        WORKZONE = 8\n        OTHERS = 9\n        \n\n    class situ(CategoryBaseEnum):\n        '''Situation of the accident'''\n        NOT_PROVIDED = -1\n        NONE = 0\n        ON_ROADWAY = 1\n        ON_EMERGENCY_LANE = 2\n        ON_SHOULDER = 3\n        ON_SIDEWALK = 4\n        ON_CYCLE_PATH = 5\n        ON_OTHER_SPECIAL_LANE = 6\n        OTHERS = 8\n\n    class vma(CategoryBaseEnum):\n        '''Maximum speed permitted at the location and time of the accident.'''\n\n    \n    class catu(CategoryBaseEnum): # \n        '''User category'''\n        UNDETERMINED = 0\n        DRIVER = 1\n        PASSENGER = 2\n        PEDESTRIAN = 3\n        \n       \n    class grav(CategoryBaseEnum):  \n        ''' Severity of the accident: The injured users are classified into three categories of victims plus the uninjured'''\n        UNKNOWN = 0\n        NO_INJURY = 1\n        KILLED = 2\n        INJURED_HOSPITALIZED = 3\n        MINOR_INJURY = 4\n        \n       \n    class sexe(CategoryBaseEnum):\n        '''User's gender'''\n        UNKNOWN = 0\n        MALE =1 \n        FEMALE = 2\n        \n       \n    class an_nais(CategoryBaseEnum): \n        '''Year of birth of the user'''\n\n    class trajet(CategoryBaseEnum):\n        '''Reason for traveling at the time of the accident'''\n        NOT_PROVIDED = 0  \n        HOME_TO_WORK = 1  \n        HOME_TO_SCHOOL = 2  \n        SHOPPING = 3  \n        PROFESSIONAL_USE = 4  \n        WALK_OR_LEISURE = 5  \n        OTHER = 9  \n        \n  \n    class secu1(CategoryBaseEnum):\n        '''The existence of a safety equipment'''\n        NOT_PROVIDED = -1  \n        NO_EQUIPMENT = 0  \n        SEATBELT = 1  \n        HELMET = 2  \n        CHILD_DEVICE = 3  \n        REFLECTIVE_VEST = 4  \n        AIRBAG_2W_3W = 5  \n        GLOVES_2W_3W = 6  \n        GLOVES_AIRBAG_2W_3W = 7  \n        NOT_DETERMINABLE = 8  \n        OTHER = 9  \n            \n\n    class jour(CategoryBaseEnum):\n        '''Day of the accident'''\n       \n    class mois(CategoryBaseEnum):\n        '''Month of the accident'''\n       \n    class an(CategoryBaseEnum):\n        '''Year of the accident'''\n       \n    class hrmn(CategoryBaseEnum):\n        '''Hour and minute of the accident'''\n       \n    class lum(CategoryBaseEnum):\n        '''Lighting conditions during the accident'''\n        DAYLIGHT = 1\n        DUSK_OR_DAWN = 2\n        NIGHT_WITHOUT_PUBLIC_LIGHT = 3\n        NIGHT_WITH_PUBLIC_LIGHT_OFF = 4\n        NIGHT_WITH_PUBLIC_LIGHT_ON = 5\n        \n       \n    class dep(CategoryBaseEnum):\n        '''Department code (INSEE code for French departments)'''\n       \n    class agg(CategoryBaseEnum):\n        '''Location of the accident: inside or outside the urban area'''\n        OUTSIDE_URBAN_AREA = 1\n        INSIDE_URBAN_AREA = 2\n        \n       \n    class int(CategoryBaseEnum):\n        '''Type of intersection where the accident occurred'''\n        NO_INTERSECTION = 1\n        X_INTERSECTION = 2\n        T_INTERSECTION = 3\n        Y_INTERSECTION = 4\n        INTERSECTION_WITH_MORE_THAN_4_BRANCHES = 5\n        ROUNDABOUT = 6\n        SQUARE = 7\n        RAILWAY_CROSSING = 8\n        OTHER_INTERSECTION = 9\n        \n       \n    class atm(CategoryBaseEnum):\n        '''Atmospheric conditions during the accident'''\n        NOT_PROVIDED = -1\n        NORMAL = 1\n        LIGHT_RAIN = 2\n        HEAVY_RAIN = 3\n        SNOW_HAIL = 4\n        FOG_SMOKE = 5\n        STRONG_WIND_STORM = 6\n        BLINDING_WEATHER = 7\n        CLOUDY_WEATHER = 8\n        OTHER = 9\n        \n       \n    class col(CategoryBaseEnum):\n        '''Type of collision'''\n        NOT_PROVIDED = -1\n        TWO_VEHICLES_FRONT = 1\n        TWO_VEHICLES_REAR = 2\n        TWO_VEHICLES_SIDE = 3\n        THREE_VEHICLES_CHAIN = 4\n        THREE_VEHICLES_MULTIPLE_COLLISIONS = 5\n        OTHER_COLLISION = 6\n        NO_COLLISION = 7\n        \n       \n    class adr(CategoryBaseEnum):\n        '''Postal address of the accident (provided for accidents inside urban areas)'''\n       \n    class lat(CategoryBaseEnum):\n        '''Latitude of the accident location'''\n       \n    class long(CategoryBaseEnum):\n        '''Longitude of the accident location'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.674606Z","iopub.status.idle":"2025-01-27T08:13:39.675050Z","shell.execute_reply":"2025-01-27T08:13:39.674860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_columns_dict = Road_Accident_Enum.to_dict()\nvalid_columns = valid_columns_dict.keys()\nprint(valid_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.675920Z","iopub.status.idle":"2025-01-27T08:13:39.676351Z","shell.execute_reply":"2025-01-27T08:13:39.676162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(csv_file, decimal=',')\ndata = df#df.sample(frac=0.1, random_state=random_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.677352Z","iopub.status.idle":"2025-01-27T08:13:39.677831Z","shell.execute_reply":"2025-01-27T08:13:39.677621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = data[[col for col in data.columns if col in valid_columns]]\nprint(data.isna().sum())\n\n\ndata['hrmn'] = data['hrmn'].astype('object')\nprint(data.info())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.678610Z","iopub.status.idle":"2025-01-27T08:13:39.679052Z","shell.execute_reply":"2025-01-27T08:13:39.678861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['hrmn'] = data['hrmn'].astype(str).str.replace(r'\\D', '', regex=True)\n\n\ndata['hrmn'] = data['hrmn'].str.zfill(4)  \n\n\ndata['hour'] = data['hrmn'].str[:2].astype(int)\ndata['minute'] = data['hrmn'].str[2:].astype(int)\n\n\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.679774Z","iopub.status.idle":"2025-01-27T08:13:39.680199Z","shell.execute_reply":"2025-01-27T08:13:39.680011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = df[[\"an\", \"mois\", \"jour\",\"hrmn\"]].isna().sum()\nprint(\"Missing values:\\n\", missing_values)\n\ndf_cleaned = df.dropna(subset=[\"an\", \"mois\", \"jour\",\"hrmn\"])\n\ndf_cleaned['an'] = pd.to_numeric(df_cleaned['an'], errors='coerce')\ndf_cleaned['mois'] = pd.to_numeric(df_cleaned['mois'], errors='coerce')\ndf_cleaned['jour'] = pd.to_numeric(df_cleaned['jour'], errors='coerce')\n\ndf_cleaned['hrmn'] = df_cleaned['hrmn'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(4)  \ndf_cleaned['hour'] = df_cleaned['hrmn'].str[:2].astype(int)  \ndf_cleaned['minute'] = df_cleaned['hrmn'].str[2:].astype(int)  \n\ndf_cleaned[\"an\"] = df_cleaned[\"an\"].astype(int)\ndf_cleaned[\"mois\"] = df_cleaned[\"mois\"].astype(int)\ndf_cleaned[\"jour\"] = df_cleaned[\"jour\"].astype(int)\n\ncurrent_year = pd.Timestamp.now().year\ndf_cleaned = df_cleaned[(df_cleaned[\"an\"] >= 1900) & (df_cleaned[\"an\"] <= current_year)]\n\n\ndf_cleaned = df_cleaned[(df_cleaned[\"mois\"] >= 1) & (df_cleaned[\"mois\"] <= 12)]\n\ndf_cleaned = df_cleaned[(df_cleaned[\"jour\"] >= 1) & (df_cleaned[\"jour\"] <= 31)]\ndef is_valid_date(row):\n    try:\n        pd.Timestamp(year=row[\"an\"], month=row[\"mois\"], day=row[\"jour\"])\n        return True\n    except ValueError:\n        return False\n\n\ndf_cleaned = df_cleaned[df_cleaned.apply(is_valid_date, axis=1)]\ndf_cleaned = df_cleaned.rename(columns={'an': 'year', 'mois': 'month', 'jour': 'day'})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.681028Z","iopub.status.idle":"2025-01-27T08:13:39.681332Z","shell.execute_reply":"2025-01-27T08:13:39.681214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned[\"datetime\"] = pd.to_datetime(df_cleaned[['year','month','day','hour','minute']], errors='coerce')\n\ndf = df_cleaned.reset_index(drop=True)\nprint(\"Updated DataFrame with datetime column:\")\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.681977Z","iopub.status.idle":"2025-01-27T08:13:39.682320Z","shell.execute_reply":"2025-01-27T08:13:39.682150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from prophet import Prophet\n\n\nprophet_df = df[[\"datetime\", \"grav\"]].rename(columns={\"datetime\": \"ds\", \"grav\": \"y\"})\n\n\nmodel = Prophet(seasonality_mode='multiplicative')\nmodel.fit(prophet_df)\n\nfuture = model.make_future_dataframe(periods=365)\nforecast = model.predict(future)\n\n\n\nmodel.plot(forecast)\nplt.title(\"Accident Severity Forecast\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Severity Level\")\nplt.show()\n\nmodel.plot_components(forecast)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.683289Z","iopub.status.idle":"2025-01-27T08:13:39.683628Z","shell.execute_reply":"2025-01-27T08:13:39.683478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"forecast['year'] = forecast['ds'].dt.year\nfig = px.line(forecast, x='ds', y='yhat', \n              title=\"Forescast\",\n              labels={\"ds\": \"Time Line\", \"yhat\": \"Garv Level\"},\n              template=\"plotly_dark\"  \n             )\n\n\nfig.show()\n\nfig.write_html(\"Forecasting-2024.html\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.684621Z","iopub.status.idle":"2025-01-27T08:13:39.685010Z","shell.execute_reply":"2025-01-27T08:13:39.684836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nfrom autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.688433Z","iopub.status.idle":"2025-01-27T08:13:39.688770Z","shell.execute_reply":"2025-01-27T08:13:39.688638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = df.sample(frac=0.02, random_state=random_state)#df.head(5000)\ndata['datetime'] = pd.to_datetime(data['datetime'])\ndata['datetime']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.689954Z","iopub.status.idle":"2025-01-27T08:13:39.690261Z","shell.execute_reply":"2025-01-27T08:13:39.690143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = TimeSeriesDataFrame.from_data_frame(\n    data,\n    id_column=\"Num_Acc\",\n    timestamp_column=\"datetime\"\n)\n\n\ntrain_data ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.690829Z","iopub.status.idle":"2025-01-27T08:13:39.691101Z","shell.execute_reply":"2025-01-27T08:13:39.690989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install pmdarima","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.692832Z","iopub.status.idle":"2025-01-27T08:13:39.693177Z","shell.execute_reply":"2025-01-27T08:13:39.693034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pmdarima as pm\nmodel = pm.auto_arima(data['grav'], \n                      seasonal=True,    \n                      m=1,             \n                      trace=True)      \n\n\nprint(model.summary())\n\n\nmodel.plot_diagnostics(figsize=(10, 8))\nplt.show()\n\n\nif model.seasonal_order[3] == 0:  \n    print(\"The model is likely additive.\")\nelse:\n    print(\"The model is likely multiplicative.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.693980Z","iopub.status.idle":"2025-01-27T08:13:39.694299Z","shell.execute_reply":"2025-01-27T08:13:39.694158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['grav'].value_counts()\ndata['grav'] = data['grav']+2\ndata['grav'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.695193Z","iopub.status.idle":"2025-01-27T08:13:39.695498Z","shell.execute_reply":"2025-01-27T08:13:39.695375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\n\nresult_add = seasonal_decompose(data['grav'], model='additive', period=12)\nresult_add.plot()\nplt.title(\"Additive Decomposition\")\nplt.show()\n\n\nresult_mul = seasonal_decompose(data['grav'], model='multiplicative', period=12)\nresult_mul.plot()\nplt.title(\"Multiplicative Decomposition\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.696242Z","iopub.status.idle":"2025-01-27T08:13:39.696638Z","shell.execute_reply":"2025-01-27T08:13:39.696439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## remove anything not mainland france\nLAT_MIN, LAT_MAX = 40.0, 60.0\nLONG_MIN, LONG_MAX = -10.0, 10.0 ## approx\n\nmask = (data['lat'] >= LAT_MIN) & (data['lat'] <= LAT_MAX) & (data['long'] >= LONG_MIN) & (data['long'] <= LONG_MAX)\n\nno_data = data[~mask]\ndata = data[mask]\n\n\nprint(no_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.702115Z","iopub.status.idle":"2025-01-27T08:13:39.702402Z","shell.execute_reply":"2025-01-27T08:13:39.702276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_parquet(data):\n    if data is None:\n        raise ValueError(\"Data can't be None for Parquet Creation\")\n    obj_cols = data.select_dtypes(include =['object']).columns\n    for col in obj_cols:\n        data[col]=data[col].astype(str)\n    filepath = os.path.join(os.getcwd(),ExtensionMethods.generate_filename(\"preprocessedMerged-\", \"parquet\"))\n    data.to_parquet(filepath, engine='pyarrow',compression=\"zstd\", compression_level=10, index=False)\n    print(f\"\\n Finished Saving parquet to: {filepath}\")\n\n\ndef pre_processing_step(data):\n    #step 0 - Only take valid_cols\n    valid_columns_dict = Road_Accident_Enum.to_dict()\n    valid_columns = valid_columns_dict.keys()\n    data = data[[col for col in data.columns if col in valid_columns]]\n    print(data.columns)\n    #step 1: convert the lat and long , remove all except mainland france\n    LAT_MIN, LAT_MAX = 40.0, 60.0\n    LONG_MIN, LONG_MAX = -10.0, 10.0\n    mask = (data['lat'] >= LAT_MIN) & (data['lat'] <= LAT_MAX) & (data['long'] >= LONG_MIN) & (data['long'] <= LONG_MAX)\n    data = data[mask]\n    #step 2 : take care of 'an_nais'\n    data = data.dropna(subset=['an_nais'])\n    data['an_nais'] = pd.to_numeric(data['an_nais'])\n    #step 3: take care of addr\n    data['adr'] = data['adr'].fillna(\"UNKNOWN\")\n    create_parquet(data)\n    print(f\"\\n Finished Preprocessing\")\n    return data\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.703286Z","iopub.status.idle":"2025-01-27T08:13:39.703702Z","shell.execute_reply":"2025-01-27T08:13:39.703515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# age \ndata['age'] = 2025 - data['an_nais']\nprint(data['age'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.706695Z","iopub.status.idle":"2025-01-27T08:13:39.706989Z","shell.execute_reply":"2025-01-27T08:13:39.706869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install \"zenml[server]\" notebook","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.708739Z","iopub.status.idle":"2025-01-27T08:13:39.709097Z","shell.execute_reply":"2025-01-27T08:13:39.708914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from zenml import pipeline, step\n\n@step  # Just add this decorator\ndef load_data() -> dict:\n    training_data = [[1, 2], [3, 4], [5, 6]]\n    labels = [0, 1, 0]\n    return {'features': training_data, 'labels': labels}\n\n@step\ndef train_model(data: dict) -> None:\n    total_features = sum(map(sum, data['features']))\n    total_labels = sum(data['labels'])\n    \n    print(f\"Trained model using {len(data['features'])} data points. \"\n          f\"Feature sum is {total_features}, label sum is {total_labels}\")\n\n@pipeline  # This function combines steps together \ndef simple_ml_pipeline():\n    dataset = load_data()\n    train_model(dataset)\n\nif __name__ == \"__main__\":\n    run = simple_ml_pipeline()  # call this to run the pipeline\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:13:39.710062Z","iopub.status.idle":"2025-01-27T08:13:39.710346Z","shell.execute_reply":"2025-01-27T08:13:39.710230Z"}},"outputs":[],"execution_count":null}]}