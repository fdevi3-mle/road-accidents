{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10388047,"sourceType":"datasetVersion","datasetId":6428833}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## DataTransformer:\nA notebook to help with the transformation of `vehicle` data into the a merged format and possibly a parquet format\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:08:15.114786Z","iopub.execute_input":"2025-01-08T16:08:15.115096Z","iopub.status.idle":"2025-01-08T16:08:15.134064Z","shell.execute_reply.started":"2025-01-08T16:08:15.115073Z","shell.execute_reply":"2025-01-08T16:08:15.133010Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/road-accidents-2019-2023/vehicles-2020.csv\n/kaggle/input/road-accidents-2019-2023/char-2019.csv\n/kaggle/input/road-accidents-2019-2023/char-2021.csv\n/kaggle/input/road-accidents-2019-2023/place-2022.csv\n/kaggle/input/road-accidents-2019-2023/users-2023.csv\n/kaggle/input/road-accidents-2019-2023/users-2021.csv\n/kaggle/input/road-accidents-2019-2023/vehicles-2021.csv\n/kaggle/input/road-accidents-2019-2023/char-2020.csv\n/kaggle/input/road-accidents-2019-2023/place-2019.csv\n/kaggle/input/road-accidents-2019-2023/users-2019.csv\n/kaggle/input/road-accidents-2019-2023/place-2021.csv\n/kaggle/input/road-accidents-2019-2023/users-2020.csv\n/kaggle/input/road-accidents-2019-2023/char-2023.csv\n/kaggle/input/road-accidents-2019-2023/users-2022.csv\n/kaggle/input/road-accidents-2019-2023/vehicles-2022.csv\n/kaggle/input/road-accidents-2019-2023/vehicles-2019.csv\n/kaggle/input/road-accidents-2019-2023/place-2020.csv\n/kaggle/input/road-accidents-2019-2023/place-2023.csv\n/kaggle/input/road-accidents-2019-2023/vehicles-2023.csv\n/kaggle/input/road-accidents-2019-2023/char-2022.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%time\n## all imports\nimport polars as pl\nimport pyarrow.parquet as pq\nimport dask.dataframe as dd\nimport os\nimport shutil\nimport json\nfrom enum import Enum\nfrom datetime import datetime\nfrom ydata_profiling import ProfileReport\nfrom pathlib import Path\nimport random\n\n#For excel stuff\nimport openpyxl\nfrom openpyxl.drawing.image import Image\n\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Concurrency\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\nimport time\n\n#  Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random state\nrandom_state = 42\n# Set figure size\nplt.rcParams[\"figure.figsize\"] = (20, 20)\n\n\n## Set the static file locactions\nfilepaths = {'vehicles':\n    {\n    2019: '/kaggle/input/road-accidents-2019-2023/vehicles-2019.csv',\n    2020: '/kaggle/input/road-accidents-2019-2023/vehicles-2020.csv',\n    2021: '/kaggle/input/road-accidents-2019-2023/vehicles-2021.csv',\n    2022: '/kaggle/input/road-accidents-2019-2023/vehicles-2022.csv',\n    2023: '/kaggle/input/road-accidents-2019-2023/vehicles-2023.csv',\n    },\n    'users':{\n        2019: '/kaggle/input/road-accidents-2019-2023/users-2019.csv',\n        2020: '/kaggle/input/road-accidents-2019-2023/users-2020.csv',\n        2021: '/kaggle/input/road-accidents-2019-2023/users-2021.csv',\n        2022: '/kaggle/input/road-accidents-2019-2023/users-2022.csv',\n        2023: '/kaggle/input/road-accidents-2019-2023/users-2023.csv'\n    },\n    'places': {\n        2019: '/kaggle/input/road-accidents-2019-2023/place-2019.csv',\n        2020: '/kaggle/input/road-accidents-2019-2023/place-2020.csv',\n        2021: '/kaggle/input/road-accidents-2019-2023/place-2021.csv',\n        2022: '/kaggle/input/road-accidents-2019-2023/place-2022.csv',\n        2023: '/kaggle/input/road-accidents-2019-2023/place-2023.csv'\n    },\n    'characteristics':{\n        2019: '/kaggle/input/road-accidents-2019-2023/char-2019.csv',\n        2020: '/kaggle/input/road-accidents-2019-2023/char-2020.csv',\n        2021: '/kaggle/input/road-accidents-2019-2023/char-2021.csv',\n        2022: '/kaggle/input/road-accidents-2019-2023/char-2022.csv',\n        2023: '/kaggle/input/road-accidents-2019-2023/char-2023.csv'\n    }\n             \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:12:03.480709Z","iopub.execute_input":"2025-01-08T19:12:03.481153Z","iopub.status.idle":"2025-01-08T19:12:03.490961Z","shell.execute_reply.started":"2025-01-08T19:12:03.481123Z","shell.execute_reply":"2025-01-08T19:12:03.489341Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 170 µs, sys: 0 ns, total: 170 µs\nWall time: 176 µs\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"class ExtensionMethods:\n    @staticmethod\n    def generate_filename(filename=None,extension=None):\n        current_datetime = datetime.now()\n        f = current_datetime.strftime(\"%Y_%m_%d_%H%M\")\n        if (filename is None) or (extension is None):\n            return str(f)\n        else:\n            stitched_f = str(filename)+\"_\"+str(f)+\".\"+str(extension)\n            return str(stitched_f)\n\n    @staticmethod\n    def get_file_name_without_extension(filename):\n        if filename == None:\n            return \"Provide a file\"\n        return Path(filename).stem\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:08:22.047750Z","iopub.execute_input":"2025-01-08T16:08:22.048403Z","iopub.status.idle":"2025-01-08T16:08:22.054786Z","shell.execute_reply.started":"2025-01-08T16:08:22.048373Z","shell.execute_reply":"2025-01-08T16:08:22.053352Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"%%time\nclass DataTransformer:\n    def __init__(self,filedict,sep=';'): #mostly the sep is fixed with \";\", just incase\n        if filedict is None or not bool(filedict): ## checks if none or empty\n            raise ValueError(\"Provide a File Path Dictionary\")\n        self.filedict = filedict\n        self.sep = sep\n        self.key = [key for key in self.filedict] ## Here key means which type of file ex. vehicle, user...\n        self.years  = self.get_years()\n        self.dirpath = self.create_dir()\n        self._data = None\n        \n        \n\n    def get_years(self):\n        _years= []\n        for value in self.filedict.values():\n            for key, val in value.items():\n                _years.append(key)\n        return list(set(_years))\n        \n    def create_dir(self):\n        merged_path = os.path.join(os.getcwd(),'Merged')\n        if not os.path.exists(merged_path):\n            os.makedirs(merged_path)\n        return merged_path\n\n\n    def _datalist_creator(self,year=None):\n        '''Creates a list consisting [vehicle,user,char,place] per year where the vals are the corrs Dataframe'''\n        _dataframe = []\n        if year is None:\n            raise ValueError(\"year cannot be None\")\n        for key, value in self.filedict.items():\n            _filename = self.filedict[key][year]\n            print(f\"\\n Reading {key} for year {year}\")\n            _df =  pd.read_csv(_filename,sep=self.sep)\n            _dataframe.append(_df)\n        return _dataframe\n    \n    def _merge(self,year=None):\n        if year is None:\n            raise ValueError(\"year cannot be None\")\n        _data = self._datalist_creator(year)\n        if not _data:\n            raise ValueError(\"_Datalist is empty\")\n        _merged_df = _data[0]\n        for df in _data[1:]:\n            _merged_df = pd.merge(_merged_df,df)\n        return _merged_df\n\n    def concat_all_merged(self):\n        _mega = {}\n        _dfs = []\n        for year in self.years:\n            print(f\"\\n Merging Year {year}\")\n            _mega[year]= self._merge(year)\n        for key, value in _mega.items():\n            print(f\"\\n Concating for {key}\")\n            value['csv_info'] = key\n            _dfs.append(value)\n        _concated = pd.concat(_dfs)\n        self._data = _concated\n        return _concated    \n        \n   \n    def create_csv(self,data):\n        if data is None:\n            raise ValueError(\"Data cant be None for csv creation\")\n        filepath = os.path.join(self.dirpath,ExtensionMethods.generate_filename(f\"merged-{'-'.join(self.key)}\", \"csv\"))\n        data.to_csv(filepath,index=False)\n        print(f\"\\n Finished Saving csv to: {filepath}\")\n        \n    def create_parquet(self,data):\n        if data is None:\n            raise ValueError(\"Data can't be None for Parquet Creation\")\n        data = self.concat_all_merged()\n        obj_cols = data.select_dtypes(include =['object']).columns\n        for col in obj_cols:\n            data[col]=data[col].astype(str)\n        filepath = os.path.join(self.dirpath,ExtensionMethods.generate_filename(f\"merged-{'-'.join(self.key)}\", \"parquet\"))\n        data.to_parquet(filepath, engine='pyarrow',compression=\"zstd\", compression_level=10, index=False)\n        print(f\"\\n Finished Saving parquet to: {filepath}\")\n        \n    def create_feather(self,data):\n        if data is None:\n            raise ValueError(\"Data can't be none for Feather creation\")\n        obj_cols = data.select_dtypes(include =['object']).columns\n        for col in obj_cols:\n            data[col]=data[col].astype(str)\n        filepath = os.path.join(self.dirpath,ExtensionMethods.generate_filename(f\"merged-{'-'.join(self.key)}\", \"feather\"))\n        data.to_parquet(filepath, compression=\"zstd\", compression_level=10)\n        print(f\"\\n Finished Saving feather to: {filepath}\")\n        \n\n        \n    def _do_magic(self):\n        _data = self.concat_all_merged()\n        funcs = [self.create_feather,self.create_parquet, self.create_csv]\n        with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n            futures = [executor.submit(func,_data) for func in funcs]\n        for future in as_completed(futures):\n            print(f\"Result: {future.result()}\")\n\n    \n    def create_slice(self,sample_size=0.2):\n        '''Get a random slice of data . Use this for local testing . It will be quite imbalanced and '''\n        if self._data is None:\n            self._data = self.concat_all_merged()\n        data = self._data\n        _rand= random.randint(1, len(data))\n        print(f\" Creating a Random Sample of {sample_size*100}% of data with rand: {_rand}\")\n        sampled_df = data.sample(frac=sample_size,random_state=_rand)\n        return sampled_df\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:12:41.424121Z","iopub.execute_input":"2025-01-08T19:12:41.424598Z","iopub.status.idle":"2025-01-08T19:12:41.439596Z","shell.execute_reply.started":"2025-01-08T19:12:41.424559Z","shell.execute_reply":"2025-01-08T19:12:41.438207Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 40 µs, sys: 4 µs, total: 44 µs\nWall time: 50.8 µs\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"%%time\ndtransformer = DataTransformer(filedict=filepaths)\na = dtransformer.create_slice(sample_size=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:22:40.367079Z","iopub.execute_input":"2025-01-08T19:22:40.367487Z","iopub.status.idle":"2025-01-08T19:22:46.748078Z","shell.execute_reply.started":"2025-01-08T19:22:40.367457Z","shell.execute_reply":"2025-01-08T19:22:46.746880Z"}},"outputs":[{"name":"stdout","text":"\n Merging Year 2019\n\n Reading vehicles for year 2019\n\n Reading users for year 2019\n\n Reading places for year 2019\n\n Reading characteristics for year 2019\n\n Merging Year 2020\n\n Reading vehicles for year 2020\n\n Reading users for year 2020\n\n Reading places for year 2020\n\n Reading characteristics for year 2020\n\n Merging Year 2021\n\n Reading vehicles for year 2021\n\n Reading users for year 2021\n\n Reading places for year 2021\n\n Reading characteristics for year 2021\n\n Merging Year 2022\n\n Reading vehicles for year 2022\n\n Reading users for year 2022\n\n Reading places for year 2022\n\n Reading characteristics for year 2022\n\n Merging Year 2023\n\n Reading vehicles for year 2023\n\n Reading users for year 2023\n\n Reading places for year 2023\n\n Reading characteristics for year 2023\n\n Concating for 2019\n\n Concating for 2020\n\n Concating for 2021\n\n Concating for 2022\n\n Concating for 2023\n Creating a Random Sample of 10.0% of data with rand: 251588\nCPU times: user 6.05 s, sys: 313 ms, total: 6.36 s\nWall time: 6.37 s\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"b = dtransformer.create_slice(sample_size=0.25)\nprop = b['csv_info'].value_counts(normalize=True)\nprint(prop)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:22:51.167255Z","iopub.execute_input":"2025-01-08T19:22:51.167774Z","iopub.status.idle":"2025-01-08T19:22:51.648155Z","shell.execute_reply.started":"2025-01-08T19:22:51.167733Z","shell.execute_reply":"2025-01-08T19:22:51.646911Z"}},"outputs":[{"name":"stdout","text":" Creating a Random Sample of 25.0% of data with rand: 648584\ncsv_info\n2023    0.250611\n2019    0.202486\n2021    0.195469\n2022    0.191529\n2020    0.159905\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}