{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b145abbb",
   "metadata": {
    "papermill": {
     "duration": 0.002967,
     "end_time": "2025-01-06T21:44:59.851488",
     "exception": false,
     "start_time": "2025-01-06T21:44:59.848521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataTransformer:\n",
    "A notebook to help with the transformation of `vehicle` data into the a merged format and possibly a parquet format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5ee4ed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-06T21:44:59.858301Z",
     "iopub.status.busy": "2025-01-06T21:44:59.857960Z",
     "iopub.status.idle": "2025-01-06T21:45:00.835174Z",
     "shell.execute_reply": "2025-01-06T21:45:00.833582Z"
    },
    "papermill": {
     "duration": 0.983175,
     "end_time": "2025-01-06T21:45:00.837416",
     "exception": false,
     "start_time": "2025-01-06T21:44:59.854241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/road-accidents-2019-2023/vehicles-2020.csv\n",
      "/kaggle/input/road-accidents-2019-2023/char-2019.csv\n",
      "/kaggle/input/road-accidents-2019-2023/char-2021.csv\n",
      "/kaggle/input/road-accidents-2019-2023/place-2022.csv\n",
      "/kaggle/input/road-accidents-2019-2023/users-2023.csv\n",
      "/kaggle/input/road-accidents-2019-2023/users-2021.csv\n",
      "/kaggle/input/road-accidents-2019-2023/vehicles-2021.csv\n",
      "/kaggle/input/road-accidents-2019-2023/char-2020.csv\n",
      "/kaggle/input/road-accidents-2019-2023/place-2019.csv\n",
      "/kaggle/input/road-accidents-2019-2023/users-2019.csv\n",
      "/kaggle/input/road-accidents-2019-2023/place-2021.csv\n",
      "/kaggle/input/road-accidents-2019-2023/users-2020.csv\n",
      "/kaggle/input/road-accidents-2019-2023/char-2023.csv\n",
      "/kaggle/input/road-accidents-2019-2023/users-2022.csv\n",
      "/kaggle/input/road-accidents-2019-2023/vehicles-2022.csv\n",
      "/kaggle/input/road-accidents-2019-2023/vehicles-2019.csv\n",
      "/kaggle/input/road-accidents-2019-2023/place-2020.csv\n",
      "/kaggle/input/road-accidents-2019-2023/place-2023.csv\n",
      "/kaggle/input/road-accidents-2019-2023/vehicles-2023.csv\n",
      "/kaggle/input/road-accidents-2019-2023/char-2022.csv\n",
      "/kaggle/input/pm-74093556-at-01-06-2025-21-44-36/__script__.py\n",
      "/kaggle/input/pm-74093556-at-01-06-2025-21-44-36/__results__.html\n",
      "/kaggle/input/pm-74093556-at-01-06-2025-21-44-36/input_requirements.txt\n",
      "/kaggle/input/pm-74093556-at-01-06-2025-21-44-36/__script__.ipynb\n",
      "/kaggle/input/pm-74093556-at-01-06-2025-21-44-36/__output__.json\n",
      "/kaggle/input/pm-74093556-at-01-06-2025-21-44-36/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f51534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T21:45:00.844770Z",
     "iopub.status.busy": "2025-01-06T21:45:00.844198Z",
     "iopub.status.idle": "2025-01-06T21:45:09.525037Z",
     "shell.execute_reply": "2025-01-06T21:45:09.523869Z"
    },
    "papermill": {
     "duration": 8.686398,
     "end_time": "2025-01-06T21:45:09.526993",
     "exception": false,
     "start_time": "2025-01-06T21:45:00.840595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 s, sys: 973 ms, total: 5.62 s\n",
      "Wall time: 8.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## all imports\n",
    "import polars as pl\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "from ydata_profiling import ProfileReport\n",
    "from pathlib import Path\n",
    "\n",
    "#For excel stuff\n",
    "import openpyxl\n",
    "from openpyxl.drawing.image import Image\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Concurrency\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "#  Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random state\n",
    "random_state = 42\n",
    "# Set figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "\n",
    "\n",
    "## Set the static file locactions\n",
    "filepaths = {'vehicles':\n",
    "    {\n",
    "    2019: '/kaggle/input/road-accidents-2019-2023/vehicles-2019.csv',\n",
    "    2020: '/kaggle/input/road-accidents-2019-2023/vehicles-2020.csv',\n",
    "    2021: '/kaggle/input/road-accidents-2019-2023/vehicles-2021.csv',\n",
    "    2022: '/kaggle/input/road-accidents-2019-2023/vehicles-2022.csv',\n",
    "    2023: '/kaggle/input/road-accidents-2019-2023/vehicles-2023.csv',\n",
    "    },\n",
    "    'users':{\n",
    "        2019: '/kaggle/input/road-accidents-2019-2023/users-2019.csv',\n",
    "        2020: '/kaggle/input/road-accidents-2019-2023/users-2020.csv',\n",
    "        2021: '/kaggle/input/road-accidents-2019-2023/users-2021.csv',\n",
    "        2022: '/kaggle/input/road-accidents-2019-2023/users-2022.csv',\n",
    "        2023: '/kaggle/input/road-accidents-2019-2023/users-2023.csv'\n",
    "    },\n",
    "    'places': {\n",
    "        2019: '/kaggle/input/road-accidents-2019-2023/place-2019.csv',\n",
    "        2020: '/kaggle/input/road-accidents-2019-2023/place-2020.csv',\n",
    "        2021: '/kaggle/input/road-accidents-2019-2023/place-2021.csv',\n",
    "        2022: '/kaggle/input/road-accidents-2019-2023/place-2022.csv',\n",
    "        2023: '/kaggle/input/road-accidents-2019-2023/place-2023.csv'\n",
    "    },\n",
    "    'characteristics':{\n",
    "        2019: '/kaggle/input/road-accidents-2019-2023/char-2019.csv',\n",
    "        2020: '/kaggle/input/road-accidents-2019-2023/char-2020.csv',\n",
    "        2021: '/kaggle/input/road-accidents-2019-2023/char-2021.csv',\n",
    "        2022: '/kaggle/input/road-accidents-2019-2023/char-2022.csv',\n",
    "        2023: '/kaggle/input/road-accidents-2019-2023/char-2023.csv'\n",
    "    }\n",
    "             \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0732518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T21:45:09.534538Z",
     "iopub.status.busy": "2025-01-06T21:45:09.533618Z",
     "iopub.status.idle": "2025-01-06T21:45:09.540411Z",
     "shell.execute_reply": "2025-01-06T21:45:09.539262Z"
    },
    "papermill": {
     "duration": 0.012374,
     "end_time": "2025-01-06T21:45:09.542269",
     "exception": false,
     "start_time": "2025-01-06T21:45:09.529895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExtensionMethods:\n",
    "    @staticmethod\n",
    "    def generate_filename(filename=None,extension=None):\n",
    "        current_datetime = datetime.now()\n",
    "        f = current_datetime.strftime(\"%Y_%m_%d_%H%M\")\n",
    "        if (filename is None) or (extension is None):\n",
    "            return str(f)\n",
    "        else:\n",
    "            stitched_f = str(filename)+\"_\"+str(f)+\".\"+str(extension)\n",
    "            return str(stitched_f)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_name_without_extension(filename):\n",
    "        if filename == None:\n",
    "            return \"Provide a file\"\n",
    "        return Path(filename).stem\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb21463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T21:45:09.549027Z",
     "iopub.status.busy": "2025-01-06T21:45:09.548696Z",
     "iopub.status.idle": "2025-01-06T21:45:09.567062Z",
     "shell.execute_reply": "2025-01-06T21:45:09.565650Z"
    },
    "papermill": {
     "duration": 0.024138,
     "end_time": "2025-01-06T21:45:09.569174",
     "exception": false,
     "start_time": "2025-01-06T21:45:09.545036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataTransformer:\n",
    "    def __init__(self,filedict,sep=';'): #mostly the sep is fixed with \";\", just incase\n",
    "        if filedict is None or not bool(filedict): ## checks if none or empty\n",
    "            raise ValueError(\"Provide a File Path Dictionary\")\n",
    "        self.filedict = filedict\n",
    "        self.sep = sep\n",
    "        self.key = [key for key in self.filedict] ## Here key means which type of file ex. vehicle, user...\n",
    "        self.years  = self.get_years()\n",
    "        self.dirpath = self.create_dir()\n",
    "        \n",
    "\n",
    "    def get_years(self):\n",
    "        _years= []\n",
    "        for value in self.filedict.values():\n",
    "            for key, val in value.items():\n",
    "                _years.append(key)\n",
    "        return list(set(_years))\n",
    "        \n",
    "    def create_dir(self):\n",
    "        merged_path = os.path.join(os.getcwd(),'Merged')\n",
    "        if not os.path.exists(merged_path):\n",
    "            os.makedirs(merged_path)\n",
    "        return merged_path\n",
    "\n",
    "\n",
    "    def _datalist_creator(self,year=None):\n",
    "        '''Creates a list consisting [vehicle,user,char,place] per year where the vals are the corrs Dataframe'''\n",
    "        _dataframe = []\n",
    "        if year is None:\n",
    "            raise ValueError(\"year cannot be None\")\n",
    "        for key, value in self.filedict.items():\n",
    "            _filename = self.filedict[key][year]\n",
    "            print(f\"\\n Reading {key} for year {year}\")\n",
    "            _df =  pd.read_csv(_filename,sep=self.sep)\n",
    "            _dataframe.append(_df)\n",
    "        return _dataframe\n",
    "    \n",
    "    def _merge(self,year=None):\n",
    "        if year is None:\n",
    "            raise ValueError(\"year cannot be None\")\n",
    "        _data = self._datalist_creator(year)\n",
    "        if not _data:\n",
    "            raise ValueError(\"_Datalist is empty\")\n",
    "        _merged_df = _data[0]\n",
    "        for df in _data[1:]:\n",
    "            _merged_df = pd.merge(_merged_df,df)\n",
    "        return _merged_df\n",
    "\n",
    "    def concat_all_merged(self):\n",
    "        _mega = {}\n",
    "        _dfs = []\n",
    "        for year in self.years:\n",
    "            print(f\"\\n Merging Year {year}\")\n",
    "            _mega[year]= self._merge(year)\n",
    "        for key, value in _mega.items():\n",
    "            print(f\"\\n Concating for {key}\")\n",
    "            value['csv_info'] = key\n",
    "            _dfs.append(value)\n",
    "        _concated = pd.concat(_dfs)\n",
    "        return _concated    \n",
    "        \n",
    "   \n",
    "    def create_csv(self):\n",
    "        data = self.concat_all_merged() \n",
    "        filepath = os.path.join(self.dirpath,ExtensionMethods.generate_filename(f\"merged-{'-'.join(self.key)}\", \"csv\"))\n",
    "        data.to_csv(filepath,index=False)\n",
    "        print(f\"\\n Finished Saving csv to: {filepath}\")\n",
    "        \n",
    "    def create_parquet(self):\n",
    "        data = self.concat_all_merged()\n",
    "        obj_cols = data.select_dtypes(include =['object']).columns\n",
    "        for col in obj_cols:\n",
    "            data[col]=data[col].astype(str)\n",
    "        filepath = os.path.join(self.dirpath,ExtensionMethods.generate_filename(f\"merged-{'-'.join(self.key)}\", \"parquet\"))\n",
    "        data.to_parquet(filepath, engine='pyarrow',compression=\"zstd\", compression_level=10, index=False)\n",
    "        print(f\"\\n Finished Saving parquet to: {filepath}\")\n",
    "        \n",
    "    def create_feather(self):\n",
    "        data = self.concat_all_merged()\n",
    "        obj_cols = data.select_dtypes(include =['object']).columns\n",
    "        for col in obj_cols:\n",
    "            data[col]=data[col].astype(str)\n",
    "        filepath = os.path.join(self.dirpath,ExtensionMethods.generate_filename(f\"merged-{'-'.join(self.key)}\", \"feather\"))\n",
    "        data.to_parquet(filepath, compression=\"zstd\", compression_level=10)\n",
    "        print(f\"\\n Finished Saving feather to: {filepath}\")\n",
    "        \n",
    "    def create_h5(self):\n",
    "        data = self.concat_all_merged()\n",
    "        filepath = os.path.join(self.dirpath,ExtensionMethods.generate_filename(f\"merged-{'-'.join(self.key)}\", \"h5\"))\n",
    "        store= pd.HDFStore(filepath, 'w')\n",
    "        store.put('data',data)\n",
    "        print(f\"\\n Finished Saving HDF5 to: {filepath}\")\n",
    "        \n",
    "    def _do_magic(self):\n",
    "        funcs = [self.create_feather,self.create_parquet,self.create_h5, self.create_csv]\n",
    "        with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "            futures = [executor.submit(func) for func in funcs]\n",
    "        for future in as_completed(futures):\n",
    "            print(f\"Result: {future.result()}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a012dc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T21:45:09.575984Z",
     "iopub.status.busy": "2025-01-06T21:45:09.575589Z",
     "iopub.status.idle": "2025-01-06T21:45:22.381294Z",
     "shell.execute_reply": "2025-01-06T21:45:22.380041Z"
    },
    "papermill": {
     "duration": 12.811383,
     "end_time": "2025-01-06T21:45:22.383336",
     "exception": false,
     "start_time": "2025-01-06T21:45:09.571953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Merging Year 2019\n",
      "\n",
      " Reading vehicles for year 2019\n",
      "\n",
      " Reading users for year 2019\n",
      "\n",
      " Reading places for year 2019\n",
      "\n",
      " Reading characteristics for year 2019\n",
      "\n",
      " Merging Year 2020\n",
      "\n",
      " Reading vehicles for year 2020\n",
      "\n",
      " Reading users for year 2020\n",
      "\n",
      " Reading places for year 2020\n",
      "\n",
      " Reading characteristics for year 2020\n",
      "\n",
      " Merging Year 2021\n",
      "\n",
      " Reading vehicles for year 2021\n",
      "\n",
      " Reading users for year 2021\n",
      "\n",
      " Reading places for year 2021\n",
      "\n",
      " Reading characteristics for year 2021\n",
      "\n",
      " Merging Year 2022\n",
      "\n",
      " Reading vehicles for year 2022\n",
      "\n",
      " Reading users for year 2022\n",
      "\n",
      " Reading places for year 2022\n",
      "\n",
      " Reading characteristics for year 2022\n",
      "\n",
      " Merging Year 2023\n",
      "\n",
      " Reading vehicles for year 2023\n",
      "\n",
      " Reading users for year 2023\n",
      "\n",
      " Reading places for year 2023\n",
      "\n",
      " Reading characteristics for year 2023\n",
      "\n",
      " Concating for 2019\n",
      "\n",
      " Concating for 2020\n",
      "\n",
      " Concating for 2021\n",
      "\n",
      " Concating for 2022\n",
      "\n",
      " Concating for 2023\n",
      "\n",
      " Finished Saving feather to: /kaggle/working/Merged/merged-vehicles-users-places-characteristics_2025_01_06_2145.feather\n",
      "CPU times: user 10.2 s, sys: 1.2 s, total: 11.4 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtransformer = DataTransformer(filedict=filepaths)\n",
    "dtransformer.create_feather()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6428833,
     "sourceId": 10388047,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.83582,
   "end_time": "2025-01-06T21:45:23.711829",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-06T21:44:56.876009",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
